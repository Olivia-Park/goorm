{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MiniProject_SentimentAnalysis_Eng",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1H-HjK4mMe8j6cFUWeE3AQw3wkFPobvNr",
      "authorship_tag": "ABX9TyPsdlwtN3S9tFphb1xywH3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf90a48631ff4e25ae838893eb78b301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56284bb3aa524699803571e4ab218acb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e34ad6161d9d4a89a337e1785802d9eb",
              "IPY_MODEL_cb69d8bde8b842d690f6ef45bfd1ddce",
              "IPY_MODEL_df272a80492a4afbaa865040f527a597"
            ]
          }
        },
        "56284bb3aa524699803571e4ab218acb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e34ad6161d9d4a89a337e1785802d9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_10f94d6b444d443b89edae352778301a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ddd35d992914ff4b367045ba2076cb0"
          }
        },
        "cb69d8bde8b842d690f6ef45bfd1ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bb1d7411f2554430bc2cb5a3b444d24b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5be5539ad6f3451bb87a614cd2627a65"
          }
        },
        "df272a80492a4afbaa865040f527a597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f6924c1680d460db8d85be1e5c27e8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:25&lt;00:00, 19.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00287128e64741d99467d1059366ea80"
          }
        },
        "10f94d6b444d443b89edae352778301a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ddd35d992914ff4b367045ba2076cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb1d7411f2554430bc2cb5a3b444d24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5be5539ad6f3451bb87a614cd2627a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f6924c1680d460db8d85be1e5c27e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00287128e64741d99467d1059366ea80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olivia-Park/goorm/blob/main/MiniProject_SentimentAnalysis_Eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z-gmdUDdT5A"
      },
      "source": [
        "# Import requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUqQjSEtxmKk",
        "outputId": "e7a5cf1d-fd67-4ab9-f201-3f825daac8e7"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 41.1 MB/s \n",
            "\u001b[?25hCollecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 48.1 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=9eaf7b84770727e31ec2a59ace837efad923ee10699aedc4b06bcc2d697433d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=d4dc6e4ca9057ff8e0b124c043dc42bcb7adfa1fd98d4e7fad8aa185da8b1a1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmbhYHkGxtw-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERjeWCvAyDyE",
        "outputId": "0724243e-3f3f-4dbc-fae8-e1b5ad117f91"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 34.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc6kAbLadGlh"
      },
      "source": [
        "import os\n",
        "import pdb\n",
        "import wandb\n",
        "import argparse\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    AutoConfig,\n",
        "    AdamW\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZbU5JGsdazK"
      },
      "source": [
        "#1. Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0RNyZMKddSF"
      },
      "source": [
        "def make_id_file(task, tokenizer):\n",
        "    def make_data_strings(file_name):\n",
        "        data_strings = []\n",
        "        with open(os.path.join('/content/drive/MyDrive/goormtextclassificationproject', file_name), 'r', encoding='utf-8') as f:\n",
        "            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n",
        "        for item in id_file_data:\n",
        "            data_strings.append(' '.join([str(k) for k in item]))\n",
        "        return data_strings\n",
        "    \n",
        "    print('it will take some times...')\n",
        "    train_pos = make_data_strings('sentiment.train.1')\n",
        "    train_neg = make_data_strings('sentiment.train.0')\n",
        "    dev_pos = make_data_strings('sentiment.dev.1')\n",
        "    dev_neg = make_data_strings('sentiment.dev.0')\n",
        "\n",
        "    print('make id file finished!')\n",
        "    return train_pos, train_neg, dev_pos, dev_neg"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5dpmxW8dljd"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw5u1InydoaR",
        "outputId": "5df0b9b1-44ac-4205-b05d-8d07caee11b8"
      },
      "source": [
        "train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it will take some times...\n",
            "make id file finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6HBbEVIdpm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7694339d-2cd2-439f-bace-e0d49ef43f27"
      },
      "source": [
        "train_pos[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 6581 2833 1012 102',\n",
              " '101 21688 8013 2326 1012 102',\n",
              " '101 2027 2036 2031 3679 19247 1998 3256 6949 2029 2003 2428 2204 1012 102',\n",
              " '101 2009 1005 1055 1037 2204 15174 2098 7570 22974 2063 1012 102',\n",
              " '101 1996 3095 2003 5379 1012 102',\n",
              " '101 2204 3347 2833 1012 102',\n",
              " '101 2204 2326 1012 102',\n",
              " '101 11350 1997 2154 2003 25628 1998 7167 1997 19247 1012 102',\n",
              " '101 2307 2173 2005 6265 2030 3347 27962 1998 5404 1012 102',\n",
              " '101 1996 2047 2846 3504 6429 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZRqNQZXdrsl"
      },
      "source": [
        "class SentimentDataset(object):\n",
        "    def __init__(self, tokenizer, pos, neg):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for pos_sent in pos:\n",
        "            self.data += [self._cast_to_int(pos_sent.strip().split())]\n",
        "            self.label += [[1]]\n",
        "        for neg_sent in neg:\n",
        "            self.data += [self._cast_to_int(neg_sent.strip().split())]\n",
        "            self.label += [[0]]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample), np.array(self.label[index])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51VuL0Nbdt4I"
      },
      "source": [
        "train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n",
        "dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFDyhOETdv-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5e7010-68dc-4261-fd09-414b86d9bc88"
      },
      "source": [
        "for i, item in enumerate(train_dataset):\n",
        "    print(item)\n",
        "    if i == 10:\n",
        "        break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 101, 6581, 2833, 1012,  102]), array([1]))\n",
            "(array([  101, 21688,  8013,  2326,  1012,   102]), array([1]))\n",
            "(array([  101,  2027,  2036,  2031,  3679, 19247,  1998,  3256,  6949,\n",
            "        2029,  2003,  2428,  2204,  1012,   102]), array([1]))\n",
            "(array([  101,  2009,  1005,  1055,  1037,  2204, 15174,  2098,  7570,\n",
            "       22974,  2063,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 3095, 2003, 5379, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 3347, 2833, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 2326, 1012,  102]), array([1]))\n",
            "(array([  101, 11350,  1997,  2154,  2003, 25628,  1998,  7167,  1997,\n",
            "       19247,  1012,   102]), array([1]))\n",
            "(array([  101,  2307,  2173,  2005,  6265,  2030,  3347, 27962,  1998,\n",
            "        5404,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 2047, 2846, 3504, 6429, 1012,  102]), array([1]))\n",
            "(array([ 101, 2023, 2173, 2001, 2200, 2204, 1012,  102]), array([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnBrPUlYdyEi"
      },
      "source": [
        "def collate_fn_sentiment(samples):\n",
        "    input_ids, labels = zip(*samples)\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids, labels"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdd6l1SQd1mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ca7ead-92c0-42d8-eb20-4331a33bfffd"
      },
      "source": [
        "train_batch_size=64\n",
        "eval_batch_size=64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=train_batch_size,\n",
        "                                           shuffle=True, collate_fn=collate_fn_sentiment,\n",
        "                                           pin_memory=True, num_workers=4)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n",
        "                                         shuffle=False, collate_fn=collate_fn_sentiment,\n",
        "                                         num_workers=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cf90a48631ff4e25ae838893eb78b301",
            "56284bb3aa524699803571e4ab218acb",
            "e34ad6161d9d4a89a337e1785802d9eb",
            "cb69d8bde8b842d690f6ef45bfd1ddce",
            "df272a80492a4afbaa865040f527a597",
            "10f94d6b444d443b89edae352778301a",
            "5ddd35d992914ff4b367045ba2076cb0",
            "bb1d7411f2554430bc2cb5a3b444d24b",
            "5be5539ad6f3451bb87a614cd2627a65",
            "9f6924c1680d460db8d85be1e5c27e8e",
            "00287128e64741d99467d1059366ea80"
          ]
        },
        "id": "PwGXAEk_-mJe",
        "outputId": "d6f7a9fc-f180-4c4b-f459-db2149f2dfac"
      },
      "source": [
        "# random seed\n",
        "random_seed=42\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf90a48631ff4e25ae838893eb78b301",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNQLq1tcd43s"
      },
      "source": [
        "model.train()\n",
        "learning_rate = 5e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWZ9gFpxd6GV"
      },
      "source": [
        "def compute_acc(predictions, target_labels):\n",
        "    return (np.array(predictions) == np.array(target_labels)).mean()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th1Sk46td7Vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9483b90-9157-4a8f-b7ab-a7c070d53863"
      },
      "source": [
        "train_epoch = 1\n",
        "lowest_valid_loss = 9999.\n",
        "for epoch in range(train_epoch):\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
        "            tepoch.set_description(f\"Epoch {epoch}\")\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            position_ids = position_ids.to(device)\n",
        "            labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input_ids=input_ids,\n",
        "                           attention_mask=attention_mask,\n",
        "                           token_type_ids=token_type_ids,\n",
        "                           position_ids=position_ids,\n",
        "                           labels=labels)\n",
        "\n",
        "            loss = output.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "            if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n",
        "                # Evaluate the model five times per epoch\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    valid_losses = []\n",
        "                    predictions = []\n",
        "                    target_labels = []\n",
        "                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n",
        "                                                                                                desc='Eval',\n",
        "                                                                                                position=1,\n",
        "                                                                                                leave=None):\n",
        "                        input_ids = input_ids.to(device)\n",
        "                        attention_mask = attention_mask.to(device)\n",
        "                        token_type_ids = token_type_ids.to(device)\n",
        "                        position_ids = position_ids.to(device)\n",
        "                        labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "                        output = model(input_ids=input_ids,\n",
        "                                       attention_mask=attention_mask,\n",
        "                                       token_type_ids=token_type_ids,\n",
        "                                       position_ids=position_ids,\n",
        "                                       labels=labels)\n",
        "\n",
        "                        logits = output.logits\n",
        "                        loss = output.loss\n",
        "                        valid_losses.append(loss.item())\n",
        "\n",
        "                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "                        batch_labels = [int(example) for example in labels]\n",
        "\n",
        "                        predictions += batch_predictions\n",
        "                        target_labels += batch_labels\n",
        "\n",
        "                acc = compute_acc(predictions, target_labels)\n",
        "                valid_loss = sum(valid_losses) / len(valid_losses)\n",
        "                if lowest_valid_loss > valid_loss:\n",
        "                    print('Acc for model which have lower valid loss: ', acc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/6926 [00:00<?, ?batch/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Epoch 0:  20%|█▉        | 1385/6926 [11:39<47:40,  1.94batch/s, loss=0.103]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:15,  3.92it/s]\u001b[A\n",
            "Eval:   3%|▎         | 2/63 [00:00<00:12,  4.87it/s]\u001b[A\n",
            "Eval:   5%|▍         | 3/63 [00:00<00:10,  5.57it/s]\u001b[A\n",
            "Eval:   6%|▋         | 4/63 [00:00<00:10,  5.66it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:10,  5.50it/s]\u001b[A\n",
            "Eval:  10%|▉         | 6/63 [00:01<00:10,  5.45it/s]\u001b[A\n",
            "Eval:  11%|█         | 7/63 [00:01<00:09,  5.80it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 8/63 [00:01<00:09,  5.92it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:01<00:09,  5.65it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 10/63 [00:01<00:09,  5.70it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 11/63 [00:01<00:09,  5.74it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 12/63 [00:02<00:08,  5.95it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:02<00:08,  5.97it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 14/63 [00:02<00:08,  6.06it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 15/63 [00:02<00:07,  6.07it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 16/63 [00:02<00:08,  5.79it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:02<00:07,  5.82it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 18/63 [00:03<00:07,  6.04it/s]\u001b[A\n",
            "Eval:  30%|███       | 19/63 [00:03<00:07,  6.03it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 20/63 [00:03<00:07,  5.94it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:03<00:07,  5.74it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 22/63 [00:03<00:07,  5.84it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 23/63 [00:03<00:06,  6.03it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 24/63 [00:04<00:06,  5.76it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:04<00:06,  5.61it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 26/63 [00:04<00:06,  5.55it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 27/63 [00:04<00:06,  5.73it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 28/63 [00:04<00:05,  5.94it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:05<00:05,  6.09it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 30/63 [00:05<00:05,  6.00it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 31/63 [00:05<00:05,  5.79it/s]\u001b[A\n",
            "Eval:  51%|█████     | 32/63 [00:05<00:05,  5.87it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:05<00:05,  5.57it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 34/63 [00:05<00:05,  5.48it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 35/63 [00:06<00:05,  5.42it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 36/63 [00:06<00:05,  5.27it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:06<00:04,  5.20it/s]\u001b[A\n",
            "Eval:  60%|██████    | 38/63 [00:06<00:04,  5.04it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 39/63 [00:06<00:04,  4.99it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 40/63 [00:07<00:04,  5.06it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:07<00:04,  5.11it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 42/63 [00:07<00:04,  5.07it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 43/63 [00:07<00:03,  5.02it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 44/63 [00:07<00:03,  5.10it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:08<00:03,  5.05it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 46/63 [00:08<00:03,  4.91it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 47/63 [00:08<00:03,  4.94it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 48/63 [00:08<00:03,  4.95it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:08<00:02,  5.03it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 50/63 [00:09<00:02,  5.09it/s]\u001b[A\n",
            "Eval:  81%|████████  | 51/63 [00:09<00:02,  5.16it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 52/63 [00:09<00:02,  5.38it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:09<00:01,  5.36it/s]\u001b[A\n",
            "Eval:  86%|████████▌ | 54/63 [00:09<00:01,  5.28it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 55/63 [00:10<00:01,  5.25it/s]\u001b[A\n",
            "Eval:  89%|████████▉ | 56/63 [00:10<00:01,  5.15it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:10<00:01,  5.14it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 58/63 [00:10<00:00,  5.07it/s]\u001b[A\n",
            "Eval:  94%|█████████▎| 59/63 [00:10<00:00,  5.09it/s]\u001b[A\n",
            "Eval:  95%|█████████▌| 60/63 [00:11<00:00,  5.17it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:11<00:00,  5.24it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 62/63 [00:11<00:00,  5.19it/s]\u001b[A\n",
            "Eval: 100%|██████████| 63/63 [00:11<00:00,  6.02it/s]\u001b[A\n",
            "Epoch 0:  20%|██        | 1386/6926 [11:51<6:07:53,  3.98s/batch, loss=0.103]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  40%|███▉      | 2770/6926 [23:28<35:53,  1.93batch/s, loss=0.0232]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:15,  3.89it/s]\u001b[A\n",
            "Eval:   3%|▎         | 2/63 [00:00<00:12,  4.92it/s]\u001b[A\n",
            "Eval:   5%|▍         | 3/63 [00:00<00:10,  5.47it/s]\u001b[A\n",
            "Eval:   6%|▋         | 4/63 [00:00<00:10,  5.61it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:10,  5.50it/s]\u001b[A\n",
            "Eval:  10%|▉         | 6/63 [00:01<00:10,  5.38it/s]\u001b[A\n",
            "Eval:  11%|█         | 7/63 [00:01<00:09,  5.68it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 8/63 [00:01<00:09,  5.79it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:01<00:09,  5.58it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 10/63 [00:01<00:09,  5.68it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 11/63 [00:01<00:09,  5.75it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 12/63 [00:02<00:08,  5.97it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:02<00:08,  5.99it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 14/63 [00:02<00:08,  6.12it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 15/63 [00:02<00:07,  6.02it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 16/63 [00:02<00:08,  5.72it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:03<00:07,  5.75it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 18/63 [00:03<00:07,  5.99it/s]\u001b[A\n",
            "Eval:  30%|███       | 19/63 [00:03<00:07,  5.99it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 20/63 [00:03<00:07,  5.97it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:03<00:07,  5.75it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 22/63 [00:03<00:07,  5.83it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 23/63 [00:03<00:06,  6.04it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 24/63 [00:04<00:06,  5.74it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:04<00:06,  5.61it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 26/63 [00:04<00:06,  5.55it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 27/63 [00:04<00:06,  5.82it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 28/63 [00:04<00:05,  5.98it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:05<00:05,  6.11it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 30/63 [00:05<00:05,  6.13it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 31/63 [00:05<00:05,  5.83it/s]\u001b[A\n",
            "Eval:  51%|█████     | 32/63 [00:05<00:05,  5.92it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:05<00:05,  5.68it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 34/63 [00:05<00:05,  5.47it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 35/63 [00:06<00:05,  5.38it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 36/63 [00:06<00:05,  5.31it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:06<00:05,  5.16it/s]\u001b[A\n",
            "Eval:  60%|██████    | 38/63 [00:06<00:04,  5.05it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 39/63 [00:06<00:04,  5.02it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 40/63 [00:07<00:04,  5.03it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:07<00:04,  5.04it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 42/63 [00:07<00:04,  5.09it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 43/63 [00:07<00:03,  5.11it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 44/63 [00:07<00:03,  5.10it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:08<00:03,  5.00it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 46/63 [00:08<00:03,  4.95it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 47/63 [00:08<00:03,  4.96it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 48/63 [00:08<00:02,  5.02it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:08<00:02,  5.09it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 50/63 [00:09<00:02,  5.09it/s]\u001b[A\n",
            "Eval:  81%|████████  | 51/63 [00:09<00:02,  5.13it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 52/63 [00:09<00:02,  5.39it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:09<00:01,  5.33it/s]\u001b[A\n",
            "Eval:  86%|████████▌ | 54/63 [00:09<00:01,  5.25it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 55/63 [00:10<00:01,  5.24it/s]\u001b[A\n",
            "Eval:  89%|████████▉ | 56/63 [00:10<00:01,  5.16it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:10<00:01,  5.15it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 58/63 [00:10<00:00,  5.14it/s]\u001b[A\n",
            "Eval:  94%|█████████▎| 59/63 [00:10<00:00,  5.14it/s]\u001b[A\n",
            "Eval:  95%|█████████▌| 60/63 [00:11<00:00,  5.22it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:11<00:00,  5.29it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 62/63 [00:11<00:00,  5.21it/s]\u001b[A\n",
            "Eval: 100%|██████████| 63/63 [00:11<00:00,  6.00it/s]\u001b[A\n",
            "Epoch 0:  40%|████      | 2771/6926 [23:40<4:36:29,  3.99s/batch, loss=0.0232]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  60%|█████▉    | 4155/6926 [35:18<23:46,  1.94batch/s, loss=0.122] \n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:15,  4.09it/s]\u001b[A\n",
            "Eval:   3%|▎         | 2/63 [00:00<00:12,  5.02it/s]\u001b[A\n",
            "Eval:   5%|▍         | 3/63 [00:00<00:10,  5.69it/s]\u001b[A\n",
            "Eval:   6%|▋         | 4/63 [00:00<00:10,  5.76it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:10,  5.57it/s]\u001b[A\n",
            "Eval:  10%|▉         | 6/63 [00:01<00:10,  5.54it/s]\u001b[A\n",
            "Eval:  11%|█         | 7/63 [00:01<00:09,  5.87it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 8/63 [00:01<00:09,  5.95it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:01<00:09,  5.71it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 10/63 [00:01<00:09,  5.78it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 11/63 [00:01<00:09,  5.77it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 12/63 [00:02<00:08,  5.98it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:02<00:08,  5.94it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 14/63 [00:02<00:08,  6.07it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 15/63 [00:02<00:07,  6.05it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 16/63 [00:02<00:08,  5.78it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:02<00:07,  5.83it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 18/63 [00:03<00:07,  6.10it/s]\u001b[A\n",
            "Eval:  30%|███       | 19/63 [00:03<00:07,  6.06it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 20/63 [00:03<00:07,  6.00it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:03<00:07,  5.75it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 22/63 [00:03<00:06,  5.89it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 23/63 [00:03<00:06,  5.98it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 24/63 [00:04<00:06,  5.78it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:04<00:06,  5.59it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 26/63 [00:04<00:06,  5.50it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 27/63 [00:04<00:06,  5.62it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 28/63 [00:04<00:05,  5.90it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:05<00:05,  5.96it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 30/63 [00:05<00:05,  5.95it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 31/63 [00:05<00:05,  5.70it/s]\u001b[A\n",
            "Eval:  51%|█████     | 32/63 [00:05<00:05,  5.82it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:05<00:05,  5.53it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 34/63 [00:05<00:05,  5.44it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 35/63 [00:06<00:05,  5.37it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 36/63 [00:06<00:05,  5.29it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:06<00:05,  5.16it/s]\u001b[A\n",
            "Eval:  60%|██████    | 38/63 [00:06<00:05,  5.00it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 39/63 [00:06<00:04,  4.96it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 40/63 [00:07<00:04,  5.03it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:07<00:04,  5.08it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 42/63 [00:07<00:04,  5.09it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 43/63 [00:07<00:03,  5.02it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 44/63 [00:07<00:03,  5.09it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:08<00:03,  5.01it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 46/63 [00:08<00:03,  4.94it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 47/63 [00:08<00:03,  4.98it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 48/63 [00:08<00:02,  5.02it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:08<00:02,  5.10it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 50/63 [00:09<00:02,  5.08it/s]\u001b[A\n",
            "Eval:  81%|████████  | 51/63 [00:09<00:02,  5.16it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 52/63 [00:09<00:02,  5.38it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:09<00:01,  5.34it/s]\u001b[A\n",
            "Eval:  86%|████████▌ | 54/63 [00:09<00:01,  5.28it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 55/63 [00:10<00:01,  5.21it/s]\u001b[A\n",
            "Eval:  89%|████████▉ | 56/63 [00:10<00:01,  5.04it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:10<00:01,  5.12it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 58/63 [00:10<00:00,  5.09it/s]\u001b[A\n",
            "Eval:  94%|█████████▎| 59/63 [00:10<00:00,  5.11it/s]\u001b[A\n",
            "Eval:  95%|█████████▌| 60/63 [00:11<00:00,  5.19it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:11<00:00,  5.27it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 62/63 [00:11<00:00,  5.18it/s]\u001b[A\n",
            "Eval: 100%|██████████| 63/63 [00:11<00:00,  5.95it/s]\u001b[A\n",
            "Epoch 0:  60%|██████    | 4156/6926 [35:30<3:04:32,  4.00s/batch, loss=0.122]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  80%|███████▉  | 5540/6926 [47:06<11:42,  1.97batch/s, loss=0.0155]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:15,  3.90it/s]\u001b[A\n",
            "Eval:   3%|▎         | 2/63 [00:00<00:12,  4.84it/s]\u001b[A\n",
            "Eval:   5%|▍         | 3/63 [00:00<00:10,  5.52it/s]\u001b[A\n",
            "Eval:   6%|▋         | 4/63 [00:00<00:10,  5.58it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:10,  5.39it/s]\u001b[A\n",
            "Eval:  10%|▉         | 6/63 [00:01<00:10,  5.25it/s]\u001b[A\n",
            "Eval:  11%|█         | 7/63 [00:01<00:10,  5.60it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 8/63 [00:01<00:09,  5.74it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:01<00:09,  5.55it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 10/63 [00:01<00:09,  5.68it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 11/63 [00:02<00:09,  5.77it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 12/63 [00:02<00:08,  5.93it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:02<00:08,  5.90it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 14/63 [00:02<00:08,  6.10it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 15/63 [00:02<00:07,  6.01it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 16/63 [00:02<00:08,  5.69it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:03<00:07,  5.79it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 18/63 [00:03<00:07,  6.03it/s]\u001b[A\n",
            "Eval:  30%|███       | 19/63 [00:03<00:07,  5.97it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 20/63 [00:03<00:07,  5.96it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:03<00:07,  5.68it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 22/63 [00:03<00:07,  5.78it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 23/63 [00:04<00:06,  6.01it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 24/63 [00:04<00:06,  5.71it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:04<00:06,  5.54it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 26/63 [00:04<00:06,  5.51it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 27/63 [00:04<00:06,  5.64it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 28/63 [00:04<00:06,  5.81it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:05<00:05,  5.99it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 30/63 [00:05<00:05,  5.99it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 31/63 [00:05<00:05,  5.73it/s]\u001b[A\n",
            "Eval:  51%|█████     | 32/63 [00:05<00:05,  5.84it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:05<00:05,  5.57it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 34/63 [00:05<00:05,  5.36it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 35/63 [00:06<00:05,  5.28it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 36/63 [00:06<00:05,  5.23it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:06<00:05,  5.19it/s]\u001b[A\n",
            "Eval:  60%|██████    | 38/63 [00:06<00:04,  5.05it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 39/63 [00:07<00:04,  4.94it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 40/63 [00:07<00:04,  4.95it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:07<00:04,  5.01it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 42/63 [00:07<00:04,  5.08it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 43/63 [00:07<00:03,  5.05it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 44/63 [00:07<00:03,  5.03it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:08<00:03,  4.95it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 46/63 [00:08<00:03,  4.88it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 47/63 [00:08<00:03,  4.97it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 48/63 [00:08<00:02,  5.03it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:09<00:02,  5.03it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 50/63 [00:09<00:02,  5.06it/s]\u001b[A\n",
            "Eval:  81%|████████  | 51/63 [00:09<00:02,  5.10it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 52/63 [00:09<00:02,  5.33it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:09<00:01,  5.29it/s]\u001b[A\n",
            "Eval:  86%|████████▌ | 54/63 [00:09<00:01,  5.28it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 55/63 [00:10<00:01,  5.30it/s]\u001b[A\n",
            "Eval:  89%|████████▉ | 56/63 [00:10<00:01,  5.16it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:10<00:01,  5.13it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 58/63 [00:10<00:00,  5.03it/s]\u001b[A\n",
            "Eval:  94%|█████████▎| 59/63 [00:10<00:00,  5.09it/s]\u001b[A\n",
            "Eval:  95%|█████████▌| 60/63 [00:11<00:00,  5.22it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:11<00:00,  5.29it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 62/63 [00:11<00:00,  5.16it/s]\u001b[A\n",
            "Eval: 100%|██████████| 63/63 [00:11<00:00,  5.91it/s]\u001b[A\n",
            "Epoch 0:  80%|████████  | 5541/6926 [47:18<1:32:42,  4.02s/batch, loss=0.0155]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|█████████▉| 6925/6926 [58:55<00:00,  1.98batch/s, loss=0.00826]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:16,  3.81it/s]\u001b[A\n",
            "Eval:   3%|▎         | 2/63 [00:00<00:12,  4.91it/s]\u001b[A\n",
            "Eval:   5%|▍         | 3/63 [00:00<00:10,  5.48it/s]\u001b[A\n",
            "Eval:   6%|▋         | 4/63 [00:00<00:10,  5.67it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:10,  5.54it/s]\u001b[A\n",
            "Eval:  10%|▉         | 6/63 [00:01<00:10,  5.45it/s]\u001b[A\n",
            "Eval:  11%|█         | 7/63 [00:01<00:09,  5.74it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 8/63 [00:01<00:09,  5.84it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:01<00:09,  5.63it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 10/63 [00:01<00:09,  5.61it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 11/63 [00:01<00:09,  5.68it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 12/63 [00:02<00:08,  5.93it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:02<00:08,  5.92it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 14/63 [00:02<00:08,  6.05it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 15/63 [00:02<00:08,  5.99it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 16/63 [00:02<00:08,  5.65it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:03<00:08,  5.71it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 18/63 [00:03<00:07,  5.98it/s]\u001b[A\n",
            "Eval:  30%|███       | 19/63 [00:03<00:07,  5.99it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 20/63 [00:03<00:07,  5.90it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:03<00:07,  5.68it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 22/63 [00:03<00:07,  5.77it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 23/63 [00:04<00:06,  5.97it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 24/63 [00:04<00:06,  5.70it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:04<00:06,  5.58it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 26/63 [00:04<00:06,  5.56it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 27/63 [00:04<00:06,  5.78it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 28/63 [00:04<00:05,  5.83it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:05<00:05,  6.00it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 30/63 [00:05<00:05,  5.97it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 31/63 [00:05<00:05,  5.76it/s]\u001b[A\n",
            "Eval:  51%|█████     | 32/63 [00:05<00:05,  5.84it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:05<00:05,  5.60it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 34/63 [00:05<00:05,  5.47it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 35/63 [00:06<00:05,  5.31it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 36/63 [00:06<00:05,  5.28it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:06<00:05,  5.19it/s]\u001b[A\n",
            "Eval:  60%|██████    | 38/63 [00:06<00:04,  5.03it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 39/63 [00:06<00:04,  4.96it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 40/63 [00:07<00:04,  4.97it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:07<00:04,  5.02it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 42/63 [00:07<00:04,  5.08it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 43/63 [00:07<00:03,  5.06it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 44/63 [00:07<00:03,  5.06it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:08<00:03,  4.97it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 46/63 [00:08<00:03,  4.94it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 47/63 [00:08<00:03,  4.93it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 48/63 [00:08<00:02,  5.01it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:08<00:02,  5.06it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 50/63 [00:09<00:02,  5.09it/s]\u001b[A\n",
            "Eval:  81%|████████  | 51/63 [00:09<00:02,  5.07it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 52/63 [00:09<00:02,  5.29it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:09<00:01,  5.27it/s]\u001b[A\n",
            "Eval:  86%|████████▌ | 54/63 [00:09<00:01,  5.25it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 55/63 [00:10<00:01,  5.24it/s]\u001b[A\n",
            "Eval:  89%|████████▉ | 56/63 [00:10<00:01,  5.19it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:10<00:01,  5.17it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 58/63 [00:10<00:00,  5.05it/s]\u001b[A\n",
            "Eval:  94%|█████████▎| 59/63 [00:10<00:00,  5.06it/s]\u001b[A\n",
            "Eval:  95%|█████████▌| 60/63 [00:11<00:00,  5.16it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:11<00:00,  5.29it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 62/63 [00:11<00:00,  5.19it/s]\u001b[A\n",
            "Eval: 100%|██████████| 63/63 [00:11<00:00,  5.99it/s]\u001b[A\n",
            "Epoch 0: 100%|██████████| 6926/6926 [59:07<00:00,  1.95batch/s, loss=0.00826]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEbIlypNd_FD"
      },
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/goormtextclassificationproject/test_no_label.csv')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHc6s6bYeCEJ"
      },
      "source": [
        "test_dataset = test_df['Id']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47-vFQZGeDlp"
      },
      "source": [
        "def make_id_file_test(tokenizer, test_dataset):\n",
        "    data_strings = []\n",
        "    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n",
        "    for item in id_file_data:\n",
        "        data_strings.append(' '.join([str(k) for k in item]))\n",
        "    return data_strings"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OMM_KhGeFE9"
      },
      "source": [
        "test = make_id_file_test(tokenizer, test_dataset)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfDuxf7geGXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ac0219-2617-46ab-b402-490fae1fe5a9"
      },
      "source": [
        "test[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 2009 1005 1055 1037 2878 2047 3325 1998 2047 26389 2169 2051 2017 2175 1012 102',\n",
              " '101 2061 15640 2013 2019 2214 5440 1012 102',\n",
              " '101 2009 2003 1996 2087 14469 7273 1999 1996 3028 1012 102',\n",
              " '101 2079 2025 3696 1037 10084 2007 2122 2111 1012 102',\n",
              " '101 1045 2001 6091 1998 2016 2081 2033 2514 2061 6625 1998 6160 1012 102',\n",
              " '101 1996 2069 2518 2057 2363 2008 2001 2980 2001 1996 4157 1012 102',\n",
              " '101 2053 1010 2025 1996 3924 2012 2004 2226 1010 1996 3924 1999 3502 2152 1012 102',\n",
              " '101 2027 3288 2009 2041 2392 2005 2017 1998 2024 2200 14044 1012 102',\n",
              " '101 4606 1996 12043 2106 1050 1005 1056 2130 2113 2129 2000 2147 1996 3274 1012 102',\n",
              " '101 2027 2031 2019 6581 4989 1997 25025 2015 2000 5454 2013 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZB3aCILeIH9"
      },
      "source": [
        "class SentimentTestDataset(object):\n",
        "    def __init__(self, tokenizer, test):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "\n",
        "        for sent in test:\n",
        "            self.data += [self._cast_to_int(sent.strip().split())]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAYLf2GaeJo2"
      },
      "source": [
        "test_dataset = SentimentTestDataset(tokenizer, test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y58M-u31eK2M"
      },
      "source": [
        "def collate_fn_sentiment_test(samples):\n",
        "    input_ids = samples\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kbJMKQieMvm"
      },
      "source": [
        "test_batch_size = 32\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                                          shuffle=False, collate_fn=collate_fn_sentiment_test,\n",
        "                                          num_workers=2)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbCnToO-eOe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0274504d-ac71-40d5-d5c7-1168a4ecf922"
      },
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n",
        "                                                                        desc='Test',\n",
        "                                                                        position=1,\n",
        "                                                                        leave=None):\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        position_ids = position_ids.to(device)\n",
        "\n",
        "        output = model(input_ids=input_ids,\n",
        "                       attention_mask=attention_mask,\n",
        "                       token_type_ids=token_type_ids,\n",
        "                       position_ids=position_ids)\n",
        "\n",
        "        logits = output.logits\n",
        "        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "        predictions += batch_predictions"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Test:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Test:   3%|▎         | 1/32 [00:00<00:06,  4.71it/s]\u001b[A\n",
            "Test:   6%|▋         | 2/32 [00:00<00:04,  6.30it/s]\u001b[A\n",
            "Test:   9%|▉         | 3/32 [00:00<00:03,  7.46it/s]\u001b[A\n",
            "Test:  12%|█▎        | 4/32 [00:00<00:03,  7.86it/s]\u001b[A\n",
            "Test:  19%|█▉        | 6/32 [00:00<00:02,  9.03it/s]\u001b[A\n",
            "Test:  22%|██▏       | 7/32 [00:00<00:02,  9.13it/s]\u001b[A\n",
            "Test:  25%|██▌       | 8/32 [00:00<00:02,  9.32it/s]\u001b[A\n",
            "Test:  31%|███▏      | 10/32 [00:01<00:02, 10.15it/s]\u001b[A\n",
            "Test:  38%|███▊      | 12/32 [00:01<00:01, 10.61it/s]\u001b[A\n",
            "Test:  44%|████▍     | 14/32 [00:01<00:01, 10.77it/s]\u001b[A\n",
            "Test:  50%|█████     | 16/32 [00:01<00:01, 11.00it/s]\u001b[A\n",
            "Test:  56%|█████▋    | 18/32 [00:01<00:01, 11.29it/s]\u001b[A\n",
            "Test:  62%|██████▎   | 20/32 [00:02<00:01, 11.42it/s]\u001b[A\n",
            "Test:  69%|██████▉   | 22/32 [00:02<00:00, 11.40it/s]\u001b[A\n",
            "Test:  75%|███████▌  | 24/32 [00:02<00:00, 11.50it/s]\u001b[A\n",
            "Test:  81%|████████▏ | 26/32 [00:02<00:00, 11.55it/s]\u001b[A\n",
            "Test:  88%|████████▊ | 28/32 [00:02<00:00, 11.34it/s]\u001b[A\n",
            "Test:  94%|█████████▍| 30/32 [00:02<00:00, 11.12it/s]\u001b[A\n",
            "Test: 100%|██████████| 32/32 [00:03<00:00, 12.06it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oAexYeueRV9"
      },
      "source": [
        "test_df['Category'] = predictions"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blx_4_hPeTHi"
      },
      "source": [
        "test_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}